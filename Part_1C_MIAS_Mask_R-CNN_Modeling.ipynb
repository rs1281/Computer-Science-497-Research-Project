{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e8c00f",
   "metadata": {},
   "source": [
    "# Classifying Tumors in Mammograms\n",
    "\n",
    "# Part 1C - MIAS Mask R-CNN Modeling\n",
    " \n",
    "\n",
    "Documentation for a Mask R-CNN can be found [here](https://arxiv.org/abs/1703.06870). The work for this notebook followed this [tutorial](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/). \n",
    "\n",
    "The base layout was taken from the tutorial, as well as the base for the plot function at the end.\n",
    "\n",
    "The github for Mask R-CNN is originally [here](https://github.com/matterport/Mask_RCNN/) and a fork of this from [here](https://github.com/ahmedfgad/Mask-RCNN-TF2) was used due to there being various version issues that needed to be handled to get it to work properly. \n",
    "\n",
    "This method has its limitations in this context, especially because it isn't the best implentation for it initially. The training set is small, and how to apply it to normal tissue was not decided on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882117f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import utils\n",
    "'''\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a file list\n",
    "files = glob.glob('mias_data/all-mias/mdb*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f79342",
   "metadata": {},
   "source": [
    "## Splitting Data\n",
    "\n",
    "Because of how the package is setup, in function calls for the data are split into train and test. Splitting the data just by first 75% and the rest has imbalance in the testing set. Doing a train test split for file numberr improves this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(range(len(files)))\n",
    "y = list(range(len(files)))\n",
    "train_i, test_i, dummy_train, dummy_test = train_test_split(X,y,random_state = 42)\n",
    "print(len(train_i),len(test_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae4b1f",
   "metadata": {},
   "source": [
    "## Making information files\n",
    "\n",
    "This splits the base file into an XML for all of the individual files. If the image has no tumor, then a 0 pixel bounding box was assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352aa0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the data file and a temporary output file to start\n",
    "f = open(\"mias_data/all-mias/info_red.csv\", \"r\")\n",
    "f_out =  open(f'dummy.xml','w')\n",
    "#Loop until we say to leave, which is when we reach EOF\n",
    "prev_num = -1\n",
    "while True:\n",
    "    #Read in next line\n",
    "    nstr = f.readline()\n",
    "    #break at EOF\n",
    "    if len(nstr) == 0:\n",
    "        break\n",
    "    #Break up the columns\n",
    "    str_list = nstr.split()\n",
    "    #print(str_list)\n",
    "    #Get the file number\n",
    "    img_id = str_list[0][3:6]\n",
    "    #If new file, close last file, start a new one\n",
    "    if prev_num != img_id:\n",
    "        f_out.write(\"</annotation>\")\n",
    "        f_out.close()\n",
    "        f_out = open(f'mias_data/all-mias/annot/{img_id}.xml','w')\n",
    "        f_out.write(f\"\"\"<annotation>\n",
    "    <folder>all-mias.tar</folder>\n",
    "    <path>all-mias.tar/{str_list[0]}.pgm</path>\n",
    "    <source>\n",
    "        <database>Unknown</database>\n",
    "    </source>\n",
    "    <filename>{str_list[0]}</filename>\n",
    "    <size>\n",
    "        <width>1024</width>\n",
    "        <height>1024</height>\n",
    "        <depth>1</depth>\n",
    "    </size>\n",
    "    <segmented>0</segmented>\n",
    "\"\"\")\n",
    "    #If there is a turmor, put the infor\n",
    "    if len(str_list) > 3:\n",
    "        f_out.write(f\"\"\"    <object>\n",
    "        <name>tumor</name>\n",
    "        <pose>Unspecified</pose>\n",
    "        <truncated>0</truncated>\n",
    "        <difficult>0</difficult>\n",
    "        <bndbox>\n",
    "            <xmin>{int(str_list[4]) - int(str_list[6])}</xmin>\n",
    "            <ymin>{1024-int(str_list[5]) - int(str_list[6])}</ymin>\n",
    "            <xmax>{int(str_list[4]) + int(str_list[6])}</xmax>\n",
    "            <ymax>{1024-int(str_list[5]) + int(str_list[6])}</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "\"\"\")\n",
    "    #If no tumor, 0 pixel size\n",
    "    else:\n",
    "        f_out.write(f\"\"\"    <object>\n",
    "        <name>normal</name>\n",
    "        <pose>Unspecified</pose>\n",
    "        <truncated>0</truncated>\n",
    "        <difficult>0</difficult>\n",
    "        <bndbox>\n",
    "            <xmin>{0}</xmin>\n",
    "            <ymin>{0}</ymin>\n",
    "            <xmax>{0}</xmax>\n",
    "            <ymax>{0}</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "\"\"\")\n",
    "    prev_num = img_id\n",
    "    \n",
    "#Close the last file\n",
    "f_out.write(\"</annotation>\")\n",
    "f_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4b703",
   "metadata": {},
   "source": [
    "## Mammogram Dataset\n",
    "\n",
    "Mask R-CNN requires information to have the following class setup for loading the dataset, extracting bounding boxes, loading their masks, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d101729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mammogram Class\n",
    "class MammogramDataset(Dataset):\n",
    "    #Load the model\n",
    "    #is_train loads the set type, dataset_dir is where images are\n",
    "    #train_list and test_list to differntiate which file is what set\n",
    "    def load_dataset(self, dataset_dir,train_list,test_list,is_train=True):\n",
    "        #Two categories, normal and not\n",
    "        self.add_class(\"dataset\", 1, \"normal\")\n",
    "        self.add_class(\"dataset\", 2, \"tumor\")\n",
    "        files = glob.glob(dataset_dir + '/mdb*')\n",
    "        for file in files:\n",
    "            image_id = file[16:19]\n",
    "            #training set, skip if in test list\n",
    "            if is_train:\n",
    "                if int(image_id) in test_list:\n",
    "                    continue\n",
    "            #testing set, skip if in train list\n",
    "            if not is_train:\n",
    "                if int(image_id) in train_list:\n",
    "                    continue\n",
    "            img_path = file\n",
    "            ann_path = f'{dataset_dir}/annot/{image_id}.xml'\n",
    "            # add to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, \n",
    "                       annotation=ann_path,class_ids=[0,1,2])\n",
    "        \n",
    "    def extract_boxes(self, filename):\n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//object'):\n",
    "            name = box.find('name').text\n",
    "            xmin = int(box.find('./bndbox/xmin').text)\n",
    "            ymin = int(box.find('./bndbox/ymin').text)\n",
    "            xmax = int(box.find('./bndbox/xmax').text)\n",
    "            ymax = int(box.find('./bndbox/ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax, name]\n",
    "            boxes.append(coors)\n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        # print(boxes)\n",
    "        return boxes, width, height\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        # define box file location\n",
    "        path = info['annotation']\n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            #normal\n",
    "            if (box[4] == 'normal'):\n",
    "                masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "                class_ids.append(self.class_names.index('normal'))\n",
    "            #tumor\n",
    "            else:\n",
    "                masks[row_s:row_e, col_s:col_e, i] = 2\n",
    "                class_ids.append(self.class_names.index('tumor'))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fade167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a configuration for the model\n",
    "class MammogramConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"mammo_cfg\"\n",
    "\t# number of classes (background + normal + tumor)\n",
    "\tNUM_CLASSES = 1 + 1 + 1\n",
    "\t# number of training steps per epoch\n",
    "\tSTEPS_PER_EPOCH = 131\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"mammo_cfg\"\n",
    "\t# number of classes (background + normal + tumor)\n",
    "\tNUM_CLASSES = 1 + 1 + 1\n",
    "\t# simplify GPU config\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d4d92",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the training set \n",
    "train_set = MammogramDataset()\n",
    "train_set.load_dataset('mias_data/all-mias',train_i,test_i, is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the test set\n",
    "test_set = MammogramDataset()\n",
    "test_set.load_dataset('all-mias.tar',train_i,test_i, is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27540f",
   "metadata": {},
   "source": [
    "## Perform mask fit\n",
    "\n",
    "Load in the COCO dataset from the Mask R-CNN git (linked earlier) as a base. Fit the dataset, the best loss is achieved within 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c50754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare config\n",
    "# config = MammogramConfig()\n",
    "# config.display()\n",
    "# # define the model\n",
    "# model = MaskRCNN(mode='training', model_dir='./', config=config)\n",
    "# # load weights (mscoco) and exclude the output layers\n",
    "# model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# # train weights (output layers or 'heads')\n",
    "# model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=15, layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b21b9",
   "metadata": {},
   "source": [
    "## Load Previous Fit\n",
    "\n",
    "Once a fit was finished, the model needs to be loaded in inference mode to make predictions. This loads one of the previous fits here and uses that to make prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = PredictionConfig()\n",
    "model_inf = MaskRCNN(mode='inference', model_dir='./mammo_cfg20210826T1641/', config=cfg)\n",
    "# load model weights\n",
    "model_path = './mammo_cfg20210826T1641/mask_rcnn_mammo_cfg_0009.h5'\n",
    "model_inf.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a0c91",
   "metadata": {},
   "source": [
    "## Display results\n",
    "\n",
    "Function for plotting the end result with actual image and mask ( or lack there of) next to the image with guessed ROIs (or lack there of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d117b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_start and n_images help to allow for more control of output images and how many in each cycle\n",
    "def plot_actual_vs_predicted(dataset, model, cfg,n_start, n_images=20):\n",
    "    # load image and mask\n",
    "    pyplot.figure(figsize=(8,4))\n",
    "    for i in range(n_images):\n",
    "        # load the image and mask\n",
    "        image = dataset.load_image(i+n_start)\n",
    "        mask, _ = dataset.load_mask(i+n_start)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)[0]\n",
    "        # define subplot\n",
    "        pyplot.subplot(n_images, 2, i*2+1)\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(image)\n",
    "        pyplot.title('Actual')\n",
    "        # plot masks\n",
    "        for j in range(mask.shape[2]):\n",
    "            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "        # get the context for drawing boxes\n",
    "        pyplot.subplot(n_images, 2, i*2+2)\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(image)\n",
    "        pyplot.title('Predicted')\n",
    "        ax = pyplot.gca()\n",
    "        # plot each box\n",
    "        print(i+n_start,len(yhat['rois']))\n",
    "        for box in yhat['rois']:\n",
    "            # get coordinates\n",
    "            y1, x1, y2, x2 = box\n",
    "            # calculate width and height of the box\n",
    "            width, height = x2 - x1, y2 - y1\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "    # show the figure\n",
    "    pyplot.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628856ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show plots\n",
    "for i in range(20):\n",
    "    plot_actual_vs_predicted(test_set, model_inf, cfg,n_start=i,n_images = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
